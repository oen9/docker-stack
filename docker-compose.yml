version: '3'
services:

  # # for transaction we need to init cluster and add command: ["--replSet", "rs", "--keyFile", "/config/mongodb.key", "--bind_ip_all"]
  # # init mongodb.key
  # openssl rand -base64 756 > config/mongodb.key
  # chmod 400 config/mongodb.key
  # sudo chown 999:999 config/mongodb.key
  # docker-compose run mongo mongosh -u root -p secret --host mongo
  # rs.initiate({_id: "rs", version: 1, members: [ { _id: 0, host : "mongo:27017" } ] })
  #
  # # this is bad it will initiate with random hostname which change after container restart
  # # rs.initiate() # don't do it
  #
  # docker-compose run mongo mongosh -u root -p secret --host mongo
  mongo:
    image: mongo:6.0.8
    #image: mongo:6.0.9
    #image: mongo:7.0.0
    command: ["--replSet", "rs", "--keyFile", "/config/mongodb.key", "--bind_ip_all"]
    restart: always
    # hostname: mongodb-hostname # this works weird
    networks:
      default:
        aliases:
          - mognodb-hostname
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: secret
    volumes:
      - ./cache/mongodata:/data/db
      - ./config:/config
    ports:
      - 27017:27017

  mongo-express:
    image: mongo-express
    restart: always
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: secret
      ME_CONFIG_MONGODB_URL: mongodb://root:secret@mongo:27017/
    depends_on:
      - mongo

  # zookeeper:
  #   image: wurstmeister/zookeeper
  #   ports:
  #     - "2181:2181"

  # kafka:
  #   image: wurstmeister/kafka:2.13-2.7.1
  #   ports:
  #     - "9092"
  #     - "9092-9094:9092"
  #   environment:
  #     KAFKA_ADVERTISED_HOST_NAME: 172.17.0.1
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_CREATE_TOPICS: "test:3:3,response:3:3,request:3:3,offer:3:3"
  #   volumes:
  #     - /var/run/docker.sock:/var/run/docker.sock
  #     - ./cache/kafka-tmp:/tmp/
  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8.2
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: bitnami/kafka:3.5.1
    ports:
      - "9092:9092"
      - "9094:9094"
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_ENABLE_KRAFT=no
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
    depends_on:
      - zookeeper
    volumes:
      - ./storage:/storage

  # docker compose run postgres bash
  # psql -h postgres -d mydbname -U root
  postgres:
    image: postgres:12.2
    ports:
     - "5432:5432"
    environment:
      POSTGRES_DB: mydbname
      POSTGRES_USER: root
      POSTGRES_PASSWORD: secret
    volumes:
     - ./cache/postgres:/var/lib/postgresql/data

  # mkdir -p cache/pgadmin
  # chown -R 5050:5050 cache/pgadmin
  pgadmin:
    image: dpage/pgadmin4:latest
    ports:
     - "8082:80"
    depends_on:
      - postgres
    environment:
      PGADMIN_DEFAULT_EMAIL: root@root.com
      PGADMIN_DEFAULT_PASSWORD: secret
    volumes:
      - ./cache/pgadmin:/var/lib/pgadmin

  # root // rootpassword
  arangodb:
    image: arangodb:latest
    environment:
      ARANGO_ROOT_PASSWORD: rootpassword
      #ARANGO_NO_AUTH: 1
    ports:
      - 8529:8529
    volumes:
      - ./cache/arangodb_data_container:/var/lib/arangodb3
      - ./cache/arangodb_apps_data_container:/var/lib/arangodb3-apps

  couchbase:
    image: couchbase:7.0.1
    ports:
      - 8091-8094:8091-8094
      - 11210:11210
    volumes:
      - ./cache/couchbase:/opt/couchbase/var

  # mkdir -p cache/elasticsearch
  # chown -R 1000:1000 cache/elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    environment:
      - discovery.type=single-node
    ports:
      - 9200:9200
      - 9300:9300
    volumes:
      - ./cache/elasticsearch:/usr/share/elasticsearch/data
      - ./config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml

  # mkdir -p cache/elasticsearch6
  # chown -R 1000:1000 cache/elasticsearch6
  elasticsearch6:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.8.18
    environment:
      - discovery.type=single-node
    ports:
      - 9200:9200
      - 9300:9300
    volumes:
      - ./cache/elasticsearch6:/usr/share/elasticsearch/data
      - ./config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml

  kibana:
    depends_on:
      - elasticsearch
    image: docker.elastic.co/kibana/kibana:7.13.3
    ports:
      - 5601:5601
    volumes:
    - ./config/kibana.yml:/usr/share/kibana/config/kibana.yml

  # docker compose run redis bash
  # redis-cli -h 192.168.1.2 # local machine ip
  redis:
    #image: redis:6.2.4
    image: redis:latest
    command: ["redis-server", "--appendonly", "yes"]
    ports:
      - 6379:6379
    volumes:
      - ./cache/redis:/data

  # docker compose run elasticsearch-dump bash
  # mkdir -p cache/elasticsearch-dump/
  elasticsearch-dump:
    image: elasticdump/elasticsearch-dump:latest
    volumes:
      - ./cache/elasticsearch-dump:/data

  # docker compose run kafkactl consume topic
  # docker compose run --entrypoint /bin/bash kafkactl
  kafkactl:
    image: deviceinsight/kafkactl:v1.20.0
    volumes:
      - ~/.config/kafkactl/config.yml:/etc/kafkactl/config.yml
